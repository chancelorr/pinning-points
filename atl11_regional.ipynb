{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3bab736",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6952dd2a-7338-4c02-bff1-b334d162173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# System libraries\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "import configparser\n",
    "import json\n",
    "\n",
    "#Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rasterio as rs\n",
    "import rioxarray as rioxr\n",
    "\n",
    "#For geometries\n",
    "import shapely\n",
    "from shapely import box, LineString, MultiLineString, Point, Polygon, LinearRing\n",
    "from shapely.geometry.polygon import orient\n",
    "\n",
    "#For REMA\n",
    "from rasterio import plot\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "#Datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import timezone\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "\n",
    "#For plotting, ticking, and line collection\n",
    "from matplotlib import cm \n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LightSource, LinearSegmentedColormap\n",
    "from matplotlib.lines import Line2D\n",
    "import cmcrameri.cm as cmc\n",
    "import contextily as cx\n",
    "import earthpy.spatial as es\n",
    "# for legend\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.legend_handler import HandlerTuple\n",
    "\n",
    "#Personal and application specific utilities\n",
    "from utils.nsidc import download_is2\n",
    "#from utils.S2 import plotS2cloudfree, add_inset, convert_time_to_string\n",
    "from utils.utilities import is2dt2str\n",
    "import pyTMD\n",
    "\n",
    "#For error handling\n",
    "import shutil\n",
    "import traceback\n",
    "\n",
    "#For raster\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# not in use \n",
    "from ipyleaflet import Map, basemaps, Polyline, GeoData, LayersControl\n",
    "from rasterio import warp\n",
    "from rasterio.crs import CRS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa934a6-ec9c-4cb6-bbda-8a7e0d364257",
   "metadata": {},
   "source": [
    "# Specify the region, load and parse single shape file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5c188-4639-43e2-88fe-b2d5c285ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini = 'config/C-Cp_all_lumos.ini'\n",
    "\n",
    "######## Load variables ###########\n",
    "# Create a ConfigParser object\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "config.read(ini)\n",
    "\n",
    "#os and pyproj paths\n",
    "gdal_data = config.get('os', 'gdal_data')\n",
    "proj_lib = config.get('os', 'proj_lib')\n",
    "proj_data = config.get('os', 'proj_data')\n",
    "\n",
    "#path params\n",
    "basin = config.get('data', 'basin')\n",
    "region = config.get('data', 'region')\n",
    "shape = f'shapes/{basin}_{region}.shp'\n",
    "output_dir = config.get('data', 'output_dir')\n",
    "rema_path = config.get('data', 'rema_path')\n",
    "try: plot_dir = config.get('data', 'plot_dir')\n",
    "except: plot_dir='plots'\n",
    "\n",
    "#access params\n",
    "uid = config.get('access', 'uid')\n",
    "pwd = config.get('access', 'pwd')\n",
    "email = config.get('access', 'email')\n",
    "\n",
    "#Print results\n",
    "os.environ[\"GDAL_DATA\"] = gdal_data # need to specify to make gdal work\n",
    "os.environ[\"PROJ_LIB\"] = proj_lib # need to specify to make pyproj work\n",
    "os.environ[\"PROJ_DATA\"] = proj_data # need to specify to make pyproj work\n",
    "\n",
    "print(f\"basin: {basin}\")\n",
    "print(f\"region: {region}\")\n",
    "print(f\"output_dir: {output_dir}\")\n",
    "\n",
    "print(f\"uid: {uid}\")\n",
    "print(f\"pwd: {'*'*len(pwd)}\")\n",
    "print(f\"email: {email}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfe71d9",
   "metadata": {},
   "source": [
    "# Make Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dad225-8034-4e64-80a7-0b6d3d39c5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make shapes\n",
    "####\n",
    "crs_antarctica = 'EPSG:3031'\n",
    "crs_latlon = 'EPSG:4326'\n",
    "short_name = 'ATL11'\n",
    "# Read shapefile into gdf for everything\n",
    "gdf = gpd.read_file(shape).set_crs(crs_latlon, allow_override=True).to_crs(crs_antarctica)\n",
    "\n",
    "# Separate by entry type\n",
    "gdf_fl = gdf[gdf.Id_text=='Ice shelf']\n",
    "gdf_pp = gdf[(gdf.Id_text=='Ice rise or connected island')]\n",
    "gdf_ext = gpd.GeoDataFrame(geometry=[gdf_fl.apply(lambda p: Polygon(p.geometry.exterior.coords), axis=1).unary_union.union(gdf_pp.unary_union)],\n",
    "    crs=crs_antarctica).explode(ignore_index=True)\n",
    "gdf_gr = gdf[gdf.Id==1]\n",
    "gdf_ext_all = gpd.GeoDataFrame(geometry=[gdf_ext.unary_union.union(gdf_gr.unary_union)], crs=crs_antarctica)\n",
    "\n",
    "# gdf for subsetting\n",
    "#gdf = gdf[~(gdf.Id==1)]\n",
    "gdf = gpd.GeoDataFrame(geometry=[gdf.unary_union], crs=crs_antarctica)\n",
    "\n",
    "# plot the geometries\n",
    "fig1, ax1 = plt.subplots(figsize=[10, 8])\n",
    "gdf.convex_hull.plot(ax=ax1, color='None', edgecolor='black')\n",
    "gdf_ext.plot(ax=ax1, color='yellow', edgecolor='black')\n",
    "gdf_fl.plot(ax=ax1, color='red', edgecolor='black')\n",
    "gdf_pp.plot(ax=ax1, color='lightblue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd69770c-4c96-42bd-a9c8-3da774d2e0f0",
   "metadata": {},
   "source": [
    "# Define a bunch of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "641b1bb3-20f4-4220-bcd4-ef3b163d9fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data():\n",
    "    uid,pw,eml = getedcreds()\n",
    "    download_is2(short_name='ATL11', uid=uid, pwd=pw, email=eml, output_dir=output_dir, shape=shape, shape_subset=shape)\n",
    "    print('saved files to %s' % output_dir)\n",
    "    return output_dir\n",
    "\n",
    "def get_file_info():\n",
    "    search_for = '%s_' % short_name\n",
    "    search_in = output_dir + '/'\n",
    "    filelist = [search_in+f for f in os.listdir(search_in) \\\n",
    "                if os.path.isfile(os.path.join(search_in, f)) & (search_for in f) & ('.h5' in f)]\n",
    "    filelist.sort()\n",
    "    print('There are %i files.' % len(filelist))\n",
    "    \n",
    "    dirdict = dict([(x,'ascending') for x in [1,2,3,12,13,14]] + \\\n",
    "                   [(x,'descending') for x in [5,6,7,8,9,10]] + \\\n",
    "                   [(x,'turning') for x in [4,11]])\n",
    "    df_files = pd.DataFrame({'filename': filelist})\n",
    "    df_files['granule_id'] = df_files.apply(lambda x: x.filename[x.filename.rfind(search_for):], axis=1)\n",
    "    df_files['tides_filename'] = df_files.apply(lambda x: f'{output_dir}/tides/ATL11_CATS2008-v2023_TIDES_{x.granule_id[6:]}', axis=1)\n",
    "    df_files['track'] = df_files.apply(lambda x: int(x.granule_id[6:10]), axis=1)\n",
    "    df_files['region'] = df_files.apply(lambda x: int(x.granule_id[10:12]), axis=1)\n",
    "    df_files['direction'] = df_files.apply(lambda x: dirdict[x.region], axis=1)\n",
    "    df_files['cycles'] = df_files.apply(lambda x: '%s-%s' % (x.granule_id[13:15],x.granule_id[15:17]), axis=1)\n",
    "    df_files['version'] = df_files.apply(lambda x: int(x.granule_id[18:21]), axis=1)\n",
    "    df_files['release'] = df_files.apply(lambda x: int(x.granule_id[22:24]), axis=1)\n",
    "    return df_files\n",
    "\n",
    "def getedcreds():\n",
    "    # change your credentials here, do not push them to github! \n",
    "    uid = uid\n",
    "    pwd = pwd\n",
    "    email = email\n",
    "\n",
    "    # to print a message if they haven't been changed\n",
    "    if uid == '<your_nasa_earthdata_user_id>':\n",
    "        print('\\n WARNING: YOU NEED TO SET UP YOUR NASA EARTHDATA CREDENTIALS TO DOWNLOAD ICESAT-2 DATA!\\n')\n",
    "        print('  update the info in ed/edcreds.py :\\n')\n",
    "        print(\"  def getedcreds():\")\n",
    "        print(\"    # change your credentials here, do not push them to github!\")\n",
    "        print(\"    uid = '<your_nasa_earthdata_user_id>'\")\n",
    "        print(\"    pwd = '<your_nasa_earthdata_password>'\")\n",
    "        print(\"    email = '<your_nasa_earthdata_account_email>'\")\n",
    "        return None\n",
    "    else:\n",
    "        return uid, pwd, email\n",
    "\n",
    "def is2dt2str(lake_mean_delta_time):\n",
    "    lake_mean_delta_time = np.mean(lake_mean_delta_time)\n",
    "    if np.isnan(lake_mean_delta_time) | (lake_mean_delta_time == np.inf):\n",
    "        return np.nan\n",
    "    else:\n",
    "        ATLAS_SDP_epoch_datetime = datetime(2018, 1, 1, tzinfo=timezone.utc)\n",
    "        ATLAS_SDP_epoch_timestamp = datetime.timestamp(ATLAS_SDP_epoch_datetime)\n",
    "        lake_mean_timestamp = ATLAS_SDP_epoch_timestamp + lake_mean_delta_time\n",
    "        lake_mean_datetime = datetime.fromtimestamp(lake_mean_timestamp, tz=timezone.utc)\n",
    "        time_format_out = '%Y-%m-%dT%H:%M:%SZ'\n",
    "        is2time = datetime.strftime(lake_mean_datetime, time_format_out)\n",
    "        return is2time\n",
    "\n",
    "def set_axis_color(ax, axcolor):\n",
    "    ax.spines['bottom'].set_color(axcolor)\n",
    "    ax.spines['top'].set_color(axcolor) \n",
    "    ax.spines['right'].set_color(axcolor)\n",
    "    ax.spines['left'].set_color(axcolor)\n",
    "    ax.tick_params(axis='x', colors=axcolor)\n",
    "    ax.tick_params(axis='y', colors=axcolor)\n",
    "    ax.yaxis.label.set_color(axcolor)\n",
    "    ax.xaxis.label.set_color(axcolor)\n",
    "    ax.title.set_color(axcolor)\n",
    "\n",
    "def get_ground_tracks(datadict):\n",
    "    crs_latlon = 'EPSG:4326'\n",
    "    gts = []\n",
    "    for k in datadict.keys():\n",
    "        ds = datadict[k]\n",
    "        gdf_gt = gpd.GeoDataFrame(geometry=gpd.points_from_xy(ds.longitude, ds.latitude), crs=crs_latlon)\n",
    "        #for 3d geometry\n",
    "        #gdf_gt = gpd.GeoDataFrame(geometry=gpd.points_from_xy(ds.longitude, ds.latitude, ds.h_ano.sel(track=ds.track.data[0], pt=k).mean(dim='cycle_number')), crs=crs_latlon)\n",
    "        gdf_gt['pt'] = k\n",
    "        gts.append(gdf_gt)\n",
    "    gdf_gts = gpd.GeoDataFrame(geometry=pd.concat(gts).groupby(['pt'])[['geometry']].apply(lambda x: LineString(x.geometry.tolist()))\n",
    "        ).reset_index().set_crs(crs_latlon)\n",
    "    colordict = {'col0': 'darkblue', 'col1': 'rebeccapurple', 'col2': 'palevioletred', 'col3': 'thistle'}\n",
    "    gdf_gts['plotcolor'] = gdf_gts.apply(lambda x: colordict['col%s' % (int(x.pt[2])-1)], axis=1)\n",
    "    gdf_gts['track'] = ds.track.data[0]\n",
    "    \n",
    "    return gdf_gts\n",
    "\n",
    "def read_atl11(filename, track, verbose=False):\n",
    "    if verbose: print(f'reading track: {track}')\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        datadict = {}\n",
    "        pts = [x for x in f.keys() if 'pt' in x]\n",
    "        for pt in pts:\n",
    "            try:\n",
    "                vars_data = ['delta_time', 'h_corr', 'h_corr_sigma', 'h_corr_sigma_systematic', 'quality_summary']\n",
    "                vars_coords = ['cycle_number', 'latitude', 'longitude','ref_pt']\n",
    "                ds = xr.Dataset({**{v: (['x', 'cycle_number', 'track', 'pt'], f[pt][v][()][:, :, np.newaxis, np.newaxis]) for v in vars_data},\n",
    "                    'geoid': (['x', 'track', 'pt'], f[pt]['ref_surf/geoid_h'][()][:, np.newaxis, np.newaxis])},\n",
    "                    coords={'cycle_number': f[pt]['cycle_number'][()],\n",
    "                    **{v : ('x', f[pt][v][()]) for v in vars_coords[1:]}})\n",
    "                ds.coords['x'], ds['track'], ds['pt'] = np.arange(len(ds.x)), [track], [pt]\n",
    "                ds = ds.assign_coords(x_atc=('x', np.arange(len(f[pt]['latitude'][()])) * 60))\n",
    "                h_arr = np.array(ds.h_corr-ds.geoid)# go to numpy for 2-d boolean indexing\n",
    "                h_arr[ds.quality_summary>0] = np.nan\n",
    "                h_arr[(h_arr>2.5e3)+(h_arr<-50)] = np.nan\n",
    "                ds['h_corr'] = (ds.h_corr.dims, h_arr)\n",
    "                ds['h_corr'] = ds.h_corr+ds.geoid\n",
    "                datadict[pt] = ds\n",
    "            #except KeyError as e:\n",
    "            #    print(f\"KeyError: The key {e} was not found in the data source.\")\n",
    "            #except ValueError as e:\n",
    "            #    print(f\"ValueError: {e}\")\n",
    "            #except Exception as e:\n",
    "            #    print(f\"An unexpected error occurred: {e}\")\n",
    "            except: continue\n",
    "    return datadict\n",
    "\n",
    "def read_atl11_tides(filename, track):\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        tidedict = {}\n",
    "        pts = [x for x in f.keys() if 'pt' in x]\n",
    "        for pt in pts:\n",
    "            vars_data = ['delta_time', 'cycle_stats/tide_ocean']\n",
    "            vars_coords = ['cycle_number', 'latitude', 'longitude', 'ref_pt']\n",
    "            ds = xr.Dataset({v: (['x', 'cycle_number', 'track', 'pt'], f[pt][v][()][:, :, np.newaxis, np.newaxis]) for v in vars_data}, \n",
    "                    coords={'cycle_number': f[pt]['cycle_number'][()],\n",
    "                    **{v : ('x', f[pt][v][()]) for v in vars_coords[1:]}})\n",
    "            ds.coords['x'], ds['track'], ds['pt'] = np.arange(len(ds.x)), [track], [pt]\n",
    "            ds = ds.assign_coords(x_atc=('x', np.arange(len(f[pt]['latitude'][()])) * 60))\n",
    "            ds = ds.rename({'cycle_stats/tide_ocean': 'tide_cats'})\n",
    "            tide_cats = np.array(ds.tide_cats) # go to numpy for 2-d boolean indexing\n",
    "            tide_cats[tide_cats>1e5]=np.nan\n",
    "            ds['tide_cats'] = (ds.tide_cats.dims, tide_cats)\n",
    "            #ds['tide_cats'] = ds.tide_cats.interpolate_na(dim='x', method='linear').interpolate_na(dim='x', method='nearest', fill_value='extrapolate')\n",
    "            ds['tide_cats'] = ds.tide_cats.interpolate_na(dim='x', method='linear').fillna(0.0)\n",
    "            tidedict[pt] = ds\n",
    "    return tidedict\n",
    "\n",
    "def get_data(track, verbose=False):\n",
    "    # get the data\n",
    "    filename = df_files[df_files.track == track].filename.iloc[0]\n",
    "    tides_filename = df_files[df_files.track == track].tides_filename.iloc[0]\n",
    "    datadict = read_atl11(filename, track, verbose)\n",
    "    tidedict = read_atl11_tides(tides_filename, track)\n",
    "    datadict = {pt: xr.merge([datadict[pt], tidedict[pt]], join='inner', compat='override') for pt in datadict}\n",
    "    datadict = {pt: datadict[pt].assign(h_abs=(('x', 'cycle_number', 'track', 'pt'), \n",
    "        (datadict[pt]['h_corr']-datadict[pt]['geoid']-datadict[pt]['tide_cats']).data)) for pt in datadict}\n",
    "    datadict = {pt: datadict[pt].assign(h_ano=(('x', 'cycle_number', 'track', 'pt'),\n",
    "        (datadict[pt].h_abs-datadict[pt].h_abs.median(dim='cycle_number')).data)) for pt in datadict}\n",
    "    gdf_gts = get_ground_tracks(datadict).to_crs(crs_antarctica)\n",
    "    return datadict, gdf_gts\n",
    "\n",
    "'''\n",
    "def clip_data(datadict, gdf_gts, mask):\n",
    "    #clip through rectangle is faster\n",
    "    datadict_clipped = {}\n",
    "    gdf_gts_clipped_list = []\n",
    "    for pt in datadict:\n",
    "        ds=datadict[pt]\n",
    "        #select pt\n",
    "        gdf_this = gdf_gts[gdf_gts.pt==pt]\n",
    "        #convert linestring to points\n",
    "        gdf_this_pts = gpd.GeoDataFrame(geometry=gdf_gts[gdf_gts.pt==pt].get_coordinates(ignore_index=True).apply(lambda l: Point(l), axis=1), \n",
    "            crs=crs_antarctica)\n",
    "        gdf_clipped = gdf_this_pts.clip(mask.clip(gdf_this.bounds.values[0]))\n",
    "        try: gdf_gts_clipped_list.append(gdf_this.clip(mask))\n",
    "        except: continue\n",
    "        datadict_clipped[pt] = ds.sel(x=(gdf_clipped.index))\n",
    "    return datadict_clipped, pd.concat(gdf_gts_clipped_list, ignore_index=True)\n",
    "'''\n",
    "\n",
    "def clip_data(datadict, gdf_gts, mask):\n",
    "    #clip through rectangle is faster\n",
    "    datadict_clipped = {}\n",
    "    gdf_gts_clipped_list = []\n",
    "    for pt in datadict:\n",
    "        ds=datadict[pt]\n",
    "        #select pt\n",
    "        gt_this = gdf_gts[gdf_gts.pt==pt]\n",
    "        #convert linestring to points\n",
    "        gt_this_pts = gpd.GeoDataFrame(geometry=gt_this.get_coordinates(ignore_index=True).apply(lambda l: Point(l), axis=1), \n",
    "            crs=crs_antarctica)\n",
    "        gdf_clipped_index = gt_this_pts.clip(mask.clip(gt_this.bounds.values[0])).index\n",
    "        try: gdf_gts_clipped_list.append(gt_this.clip(mask))\n",
    "        except: continue\n",
    "        datadict_clipped[pt] = ds.sel(x=(gdf_clipped_index))\n",
    "    return datadict_clipped, pd.concat(gdf_gts_clipped_list, ignore_index=True)\n",
    "\n",
    "def get_ds_dict(tracklist, mask=None):\n",
    "    ds_list, gdf_gts_clipped_list = [], []\n",
    "    for p in tracklist: \n",
    "        t, c = p[0], p[1]\n",
    "        if mask is not None: datadict, gdf_gts_clipped = clip_data(datadict, gdf_gts_clipped, mask)\n",
    "        ds_add = xr.concat([datadict[pt] for pt in datadict], dim='pt')\n",
    "        ds_add['x'] = np.arange(len(ds_add.x))\n",
    "        ds_list.append(ds_add.sortby('x'))\n",
    "        gdf_gts_clipped_list.append(gdf_gts_clipped)\n",
    "    print('generating dict and gdf')\n",
    "    return {ds.track.values[0]: ds for ds in ds_list}, pd.concat(gdf_gts_clipped_list, ignore_index=True)\n",
    "\n",
    "def combine_ds_dict(ds_dict):\n",
    "    ds_list = []\n",
    "    for t in ds_dict:\n",
    "        ds = ds_dict[t]\n",
    "        if len(ds.x)!=0: \n",
    "            ds['x'] = np.arange(len(ds.x))\n",
    "            ds_list.append(ds)\n",
    "    return xr.concat(ds_list, dim='track')\n",
    "\n",
    "def get_stats(tracklist, mask=None):\n",
    "    ds_list = []\n",
    "    gdf_gts_list = []\n",
    "    for t in tracklist:\n",
    "        datadict, gdf_gts_clipped = get_data(t)\n",
    "        # subset here\n",
    "        if mask is not None: datadict, gdf_gts_clipped = clip_data(datadict, gdf_gts_clipped, mask)\n",
    "        gdf_gts_list.append(gdf_gts_clipped)\n",
    "        for pt in datadict:\n",
    "            try:\n",
    "                ds = datadict[pt]\n",
    "                h_abs = ds.h_corr - ds.geoid - ds.tide_cats\n",
    "                coords_dict = {'cycle_number': ds.cycle_number.data,\n",
    "                 'track': ds.track.data,\n",
    "                 'pt': ds.pt.data}\n",
    "                stat_dict = {'h_min': h_abs.min(dim='x'), \n",
    "                 'h_max': h_abs.max(dim='x'), \n",
    "                 'h_sum': h_abs.sum(dim='x'),\n",
    "                 'h_mean': h_abs.mean(dim='x'), \n",
    "                 'h_med': h_abs.median(dim='x'), \n",
    "                 'h_ano': ds.h_ano.median(dim='x'),\n",
    "                 'h_std': h_abs.std(dim='x', skipna=True, ddof=1),\n",
    "                 'h_var': h_abs.var(dim='x', skipna=True, ddof=1), \n",
    "                 't_count': h_abs.count(dim='x'), \n",
    "                 'pct_nan': h_abs.count(dim='x')/h_abs.sizes['x'], \n",
    "                 't_dist': h_abs.count(dim='x')*0+h_abs.x_atc.max()/1000,\n",
    "                 'tide_min': ds.tide_cats.min(dim='x'),\n",
    "                 'tide_max': ds.tide_cats.max(dim='x'),\n",
    "                 'tide_mean': ds.tide_cats.mean(dim='x'),\n",
    "                 'tide_sum': ds.tide_cats.sum(dim='x')}\n",
    "                dss = xr.Dataset({v: (['cycle_number', 'track', 'pt'], stat_dict[v].data) for v in stat_dict}, coords={v: coords_dict[v] for v in coords_dict})\n",
    "                ds_list.append(dss)\n",
    "            except: \n",
    "                continue\n",
    "            #except KeyError as e:\n",
    "            #    print(f'failed for track {t}, {pt}')\n",
    "            #    print(f\"KeyError: The key {e} was not found in the data source.\")\n",
    "            #except ValueError as e:\n",
    "            #    print(f'failed for track {t}, {pt}')\n",
    "            #    print(f\"ValueError: {e}\")\n",
    "            #except Exception as e:\n",
    "            #    print(f'failed for track {t}, {pt}')\n",
    "            #    print(f\"An unexpected error occurred: {e}\")\n",
    "    return xr.combine_by_coords(data_objects=ds_list), pd.concat(gdf_gts_list, ignore_index=True)\n",
    "        \n",
    "def reproject_raster(src, target_crs):\n",
    "    '''\n",
    "    Change crs of imported data\n",
    "    '''\n",
    "    \n",
    "    src_crs = src.crs\n",
    "    src_transform = src.transform\n",
    "    src_width = src.width\n",
    "    src_height = src.height\n",
    "\n",
    "    # Define the target CRS\n",
    "    target_crs = target_crs\n",
    "\n",
    "    # Reproject the raster data to the target CRS\n",
    "    reprojected_data, dst_transform = rs.warp.reproject(\n",
    "        source=rs.band(src, 1),\n",
    "        src_transform=src_transform,\n",
    "        src_crs=src_crs,\n",
    "        dst_crs=target_crs,\n",
    "        resampling=rs.enums.Resampling.nearest)\n",
    "    \n",
    "    return reprojected_data, dst_transform, target_crs\n",
    "\n",
    "def retry(num_attempts=1, sleep_time=5):\n",
    "    for i in range(num_attempts): \n",
    "        try: \n",
    "            download_data()\n",
    "            print(f'success on attempt {i}')\n",
    "            return\n",
    "        except Exception as e:\n",
    "            if i==num_attempts-1:\n",
    "                print(f\"The following error occurred: {e}\")\n",
    "                traceback.print_exc()\n",
    "            time.sleep(sleep_time)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508011f4",
   "metadata": {},
   "source": [
    "# Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a9ba0-d082-478f-ab30-983ea4c8972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# comment out after downloading \n",
    "#retry(20, 20)\n",
    "#download_data()\n",
    "\n",
    "df_files = get_file_info()\n",
    "df_files;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "18c49a13-3b1f-41be-942d-8db7a0139752",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#track=26\n",
    "track=727\n",
    "#track=1077\n",
    "track=392 #problem child\n",
    "#track=376 # erases all the data, but maybe it should\n",
    "track=1376 #c-cp\n",
    "datadict, gdf_gts = get_data(track)\n",
    "datadict, gdf_gts = clip_data(datadict, gdf_gts, gdf)\n",
    "pt = 'pt2'\n",
    "ds = datadict[pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1be4df-277b-47f6-856a-2fb8c6271823",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get_stats\n",
    "tracklist=[33, 26, 155, 194, 392, 727, 1077]\n",
    "dss_short_fl, gdf_gts_short_all = get_stats(tracklist, gdf_ext)\n",
    "dss_short_pp, gdf_gts_short_all_pp = get_stats(tracklist, gdf_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd2bfe3-1c23-460b-bd06-5bb044332b56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get_ds_dict\n",
    "tracklist=[33, 26, 155, 194, 392, 727, 1077]\n",
    "ds_dict_short, gdf_gts_short_all = get_ds_dict(tracklist, gdf)\n",
    "ds_dict_pp, gdf_gts_short_all_pp = get_ds_dict(tracklist, gdf_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b47183-0d69-42f3-b3f4-8ac0ff4b4f7b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Get_stats, a little bit slow\n",
    "#tracklist=df_files.track\n",
    "#dss, gdf_gts_all = get_stats(tracklist, gdf_ext)\n",
    "#dss_pp, gdf_gts_all_pp = get_stats(tracklist, gdf_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4a6022-aa0f-43b8-b17d-b3d92c354c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get_ds_dict, pretty fast\n",
    "tracklist=df_files.track\n",
    "ds_dict, gdf_gts_all = get_ds_dict(tracklist, gdf_ext_all)\n",
    "ds_dict_gr, gdf_gts_gr = get_ds_dict(tracklist, gdf_gr)\n",
    "ds_dict_fl, gdf_gts_fl = get_ds_dict(tracklist, gdf_fl)\n",
    "ds_dict_pp, gdf_gts_pp = get_ds_dict(tracklist, gdf_pp)\n",
    "\n",
    "# Combine for full dataset\n",
    "ds_all = combine_ds_dict(ds_dict)\n",
    "ds_gr = combine_ds_dict(ds_dict_gr)\n",
    "ds_fl = combine_ds_dict(ds_dict_fl)\n",
    "ds_pp = combine_ds_dict(ds_dict_pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e96710ed-f211-4602-94a1-bffe75f7d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#netcdf\n",
    "processed_out_dir = '/Volumes/nox2/Chance/processed_data/'\n",
    "ds_all.to_netcdf(f'{processed_out_dir}/{basin}_ds_all.nc')\n",
    "ds_gr.to_netcdf(f'{processed_out_dir}/{basin}_ds_gr.nc')\n",
    "ds_fl.to_netcdf(f'{processed_out_dir}/{basin}_ds_fl.nc')\n",
    "ds_pp.to_netcdf(f'{processed_out_dir}/{basin}_ds_pp.nc')\n",
    "\n",
    "gdf_gts_all.to_file(f'{processed_out_dir}/{basin}_gdf_gts_all.shp')\n",
    "gdf_gts_gr.to_file(f'{processed_out_dir}/{basin}_gdf_gts_gr.shp')\n",
    "gdf_gts_fl.to_file(f'{processed_out_dir}/{basin}_gdf_gts_fl.shp')\n",
    "gdf_gts_pp.to_file(f'{processed_out_dir}/{basin}_gdf_gts_pp.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff3d5a",
   "metadata": {},
   "source": [
    "# Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dir='/Volumes/nox2/Chance/processed_data/'\n",
    "print('Reading netCDFs into XR datasets...', end='', flush=True)\n",
    "ds_all = xr.open_dataset(f'{processed_dir}/{basin}_ds_all.nc')\n",
    "ds_gr = xr.open_dataset(f'{processed_dir}/{basin}_ds_gr.nc')\n",
    "ds_fl = xr.open_dataset(f'{processed_dir}/{basin}_ds_fl.nc')\n",
    "ds_pp = xr.open_dataset(f'{processed_dir}/{basin}_ds_pp.nc')\n",
    "print('DONE')\n",
    "\n",
    "print('Reading ESRI shapefiles into geodataframes...', end='', flush=True)\n",
    "gdf_gts_all = gpd.read_file(f'{processed_dir}/{basin}_gdf_gts_all.shp')\n",
    "gdf_gts_gr = gpd.read_file(f'{processed_dir}/{basin}_gdf_gts_gr.shp')\n",
    "gdf_gts_fl = gpd.read_file(f'{processed_dir}/{basin}_gdf_gts_fl.shp')\n",
    "gdf_gts_pp = gpd.read_file(f'{processed_dir}/{basin}_gdf_gts_pp.shp')\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2705c02-7a7a-4ed3-94ba-46ff6c186ed9",
   "metadata": {},
   "source": [
    "# Plot individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67d57f97-147a-4ab3-a5b8-035e2f6490a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate value to plot\n",
    "h_ano_lin = ds_all.h_ano.polyfit('cycle_number', deg=1, skipna=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "1f3f63d8-2bfe-4b6e-94e0-b15c3bf33039",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make plot function\n",
    "def make_plot(color_by='', dpi=600, rolling=None, vlims=[-5, 5], save=False):\n",
    "    # figure setup\n",
    "    imagery_aspect = 1.4\n",
    "    major_font_size = 12\n",
    "    minor_font_size = 10\n",
    "    line_w = 1.0\n",
    "    \n",
    "    # make figure and axes\n",
    "    fig = plt.figure(figsize=[13,8], dpi=dpi)\n",
    "    gs = fig.add_gridspec(3, 20)\n",
    "    axs = [fig.add_subplot(gs[:, :9])]\n",
    "    for i in range(3):\n",
    "        axs.append(fig.add_subplot(gs[i, 10:20]))\n",
    "    boxprops = dict(boxstyle='round', facecolor='white', alpha=0.5, edgecolor='none', pad=0.2)\n",
    "    \n",
    "    # plot the basemap and ground track\n",
    "    # We do this using the package `contextily`, which provides basemaps for plotting in matplotlib. \n",
    "    # Here we use ESRI's WordImagery basemap. \n",
    "    ax = axs[0]\n",
    "\n",
    "    with rs.open(filename) as src:\n",
    "        dem = src.read()\n",
    "        tr = src.transform\n",
    "        bbox = box(*gdf_ext.total_bounds)\n",
    "        src_masked, src_masked_tr = mask(src, shapes=[gdf_gr.geometry[0].intersection(bbox)], \n",
    "            crop=True, filled=False)\n",
    "        src_hs = np.ma.masked_array(es.hillshade(src_masked[0].filled(np.nan)), mask=src_masked.mask[0])\n",
    "        plot.show(src_hs, ax=ax, transform=src_masked_tr, cmap='Greys_r', \n",
    "            aspect='equal', vmin=-150, vmax=100)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_axis_off()\n",
    "    \n",
    "    #add ground tracks\n",
    "    lc_list=[]\n",
    "    if color_by is not None:\n",
    "        for i in range(len(gdf_gts_all)):\n",
    "            row = gdf_gts_all[i:i+1]\n",
    "            coords = row.get_coordinates()\n",
    "            cmap = cmc.vik_r\n",
    "            t = row.track.iloc[0]\n",
    "            pt = row.pt.iloc[0]\n",
    "            # Prepare segments for LineCollection\n",
    "            # Prepare segments for LineCollection\n",
    "            dc_dx = np.gradient(coords.x)\n",
    "            dc_dx_idx = np.abs(dc_dx)>1e2\n",
    "            coords.loc[dc_dx_idx, 'x'] = np.nan\n",
    "            points = np.array([coords.x, coords.y]).T.reshape(-1, 1, 2)\n",
    "            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "            # Create a LineCollection\n",
    "            lc = LineCollection(segments, cmap=cmap, norm=plt.Normalize(vlims[0], vlims[1]))\n",
    "            h_plot = h_ano_lin.sel(degree=1).sel(track=t, pt=pt).polyfit_coefficients\n",
    "            if rolling is not None: \n",
    "                h_plot = np.array(pd.Series(h_plot).rolling(window=rolling, center=True, min_periods=1, \n",
    "                    win_type='gaussian').mean(std=rolling/3))\n",
    "            lc.set_array(h_plot)\n",
    "            lc.set_linewidth(line_w)\n",
    "            lc_list.append(lc)\n",
    "            ax.add_collection(lc)\n",
    "    elif color_by is None:\n",
    "        gdf_gts_all.plot(ax=ax, color=gdf_gts_all.plotcolor, linewidth=line_w)\n",
    "        gdf_gts_pp.plot(ax=ax, color='lightblue', linewidth=line_w)\n",
    "    \n",
    "    hdls = []\n",
    "   # gdf_ext_all.apply(lambda p: p.buffer(3e3)).plot(ax=ax, color='None', edgecolor='black', label='grounded ice', linewidth=1, zorder=500)\n",
    "    gdf_pp.plot(ax=ax, color='None', edgecolor='black', label='grounded ice', linewidth=0.2, zorder=501)\n",
    "    gdf_ext.apply(lambda p: p.buffer(1e3)).plot(ax=ax, color='None', edgecolor='royalblue', label='floating ice', linewidth=0.4, zorder=502)\n",
    "    \n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, 0.96, f'ICESat-2 ATL11 Height Change\\n Basin {basin} 2019-2024', transform=ax.transAxes, \n",
    "            ha='center', va='center', fontsize=major_font_size, bbox=boxprops, zorder=502)\n",
    "        \n",
    "    \n",
    "    ax=axs[1]\n",
    "    hdls = []\n",
    "    \n",
    "    # mean values\n",
    "    \n",
    "    ano_cycle_fl = ds_fl.h_ano.median(dim=['x', 'track', 'pt'])\n",
    "    ano_cycle_pp = ds_pp.h_ano.median(dim=['x', 'track', 'pt'])\n",
    "    ax.axhline(y=0.0, linestyle='--', color='black')\n",
    "    hdl = ax.plot(ano_cycle_fl.cycle_number, (ano_cycle_fl - ano_cycle_fl.isel(cycle_number=0)), color='red', label='floating ice')\n",
    "    hdls.append(hdl)\n",
    "    hdl = ax.plot(ano_cycle_pp.cycle_number, (ano_cycle_pp - ano_cycle_pp.isel(cycle_number=0)), '-', color='lightblue', label='pinning points')\n",
    "    hdls.append(hdl)\n",
    "    # starting at 2 is 2019\n",
    "    ax.set_xlim([2, 24])\n",
    "    ax.set_ylim([-0.9, 0.9])\n",
    "    ax.set_xticks(ticks=np.arange(2, 24), minor=True)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24, 4), labels=[])\n",
    "    ax.set_yticks(ticks=[-0.5, 0.5])\n",
    "    ax.tick_params(axis='x', which='major', length=5, width=2)\n",
    "    ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "    ax.tick_params(which='both', direction='in', zorder=1, labelsize=minor_font_size)\n",
    "    ax.set_ylabel('height (m)', fontsize=minor_font_size, labelpad=-0.3)\n",
    "    ax.text(0.5, 0.96, 'Median Relative Height', transform=ax.transAxes, ha='center', va='top', \n",
    "        fontsize=major_font_size, bbox=boxprops)\n",
    "    ax.legend(loc='lower left', fontsize=minor_font_size)\n",
    "    \n",
    "    ax=axs[2]\n",
    "    \n",
    "    #anomaly (data) count\n",
    "    ano_count_fl = ds_fl.h_ano.count(dim=['x', 'track', 'pt'])\n",
    "    ano_count_pp = ds_pp.h_ano.count(dim=['x', 'track', 'pt'])\n",
    "    \n",
    "    hdls = []\n",
    "    ax.axhline(y=1.0, linestyle='--', color='black')\n",
    "    hdl = ax.plot(ano_cycle_fl.cycle_number, ano_count_fl/ano_count_fl.median(), color='red', label=f'mean = {int(ano_count_fl.mean().data)} values')\n",
    "    hdls.append(hdl)\n",
    "    hdl = ax.plot(ano_cycle_pp.cycle_number, ano_count_pp/ano_count_pp.median(), '-', color='lightblue', label=f'mean = {int(ano_count_pp.mean().data)} values')\n",
    "    hdls.append(hdl)\n",
    "    ax.set_xlim([2, 24])\n",
    "    ax.set_ylim([-0.0, 1.75])\n",
    "    ax.set_yticks([0.5, 1.0, 1.5])\n",
    "    ax.set_ylabel('count fraction', fontsize=minor_font_size)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24), minor=True)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24, 4), labels=[f'{int(c)}' for c in np.arange(2019, 2025)])\n",
    "    ax.tick_params(axis='x', which='major', length=5, width=2, labelsize=minor_font_size)\n",
    "    ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "    ax.tick_params(which='both', direction='in', zorder=1, labelsize=minor_font_size)\n",
    "    ax.text(0.5, 0.96, 'Relative Elevation Count', transform=ax.transAxes, ha='center', va='top', fontsize=major_font_size, bbox=boxprops)\n",
    "    ax.legend(loc='lower left', fontsize=minor_font_size)\n",
    "    \n",
    "    # remove extra axes if no data\n",
    "    axs[3].axis('off')\n",
    "    \n",
    "    # Create a ScalarMappable with the same colormap and normalization\n",
    "    norm = mcolors.Normalize(vmin=vlims[0], vmax=vlims[1])\n",
    "    sm = cm.ScalarMappable(cmap=cmc.vik_r, norm=norm)\n",
    "    sm.set_array([])  # Only needed for older versions of matplotlib\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Add the inset axis\n",
    "    pos = axs[0].get_position()\n",
    "    cax_pos = [pos.x0+pos.width*0.63, pos.y0+0.13, pos.width*0.25, pos.height*0.02]\n",
    "    cax = fig.add_axes(cax_pos)\n",
    "    #fig.patches.append(Rectangle((cax_pos[0]-, cax_pos[1]), cax_pos[2]*1.25, cax_pos[3]*2,\n",
    "    #    transform=fig.transFigure, color='white', zorder=1))\n",
    "    \n",
    "    # Add a colorbar to the plot, with a specific location\n",
    "    cbar = plt.colorbar(sm, cax=cax, orientation='horizontal', fraction=0.1, pad=0.0)\n",
    "    cbar.ax.tick_params(labelsize=minor_font_size) \n",
    "    cbar.set_label('height change \\n(m yr$^{-1}$)', fontsize=minor_font_size)\n",
    "    cbar.outline.set_edgecolor('black')\n",
    "    cbar.outline.set_linewidth(0.5)\n",
    "    set_axis_color(cax, 'black')\n",
    "    \n",
    "    # Customize the colorbar ticks if needed\n",
    "    cbar.set_ticks([-1, 0, 1])\n",
    "    #cbar.set_ticklabels(['0', '0.2', '0.4', '0.6', '0.8', '1'])\n",
    "    \n",
    "    plotname = f'/Users/ccroberts/Desktop/{basin}_dhdt.png'\n",
    "    if rolling is not None: plotname = f'/Users/ccroberts/Desktop/{basin}_dhdt_avg{rolling}.png'\n",
    "    if save: fig.savefig(plotname, dpi=dpi, bbox_inches='tight', transparent=False)\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b22f587-c084-410b-8d7e-f412ab77a62b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fig = make_plot(color_by='', dpi=400, vlims=[-1, 1], rolling=None, save=False)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "cbf3e52a-1e73-4c66-8295-2f1f33a7165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make plot function\n",
    "def make_map(color_by='', dpi=600, rolling=None, vlims=[-5, 5], save=False, transparent=True):\n",
    "    # figure setup\n",
    "    major_font_size = 12\n",
    "    minor_font_size = 10\n",
    "    line_w = 0.5\n",
    "    \n",
    "    # make figure and axes\n",
    "    fig, ax = plt.subplots(figsize=[13,8], dpi=dpi)\n",
    "    \n",
    "    # plot the basemap and ground tracks\n",
    "\n",
    "    with rs.open(rema_path) as src:\n",
    "        dem = src.read()\n",
    "        tr = src.transform\n",
    "        bbox = box(*gdf_ext_all.total_bounds)\n",
    "        src_masked, src_masked_tr = mask(src, shapes=[gdf_ext_all.geometry[0]], \n",
    "            crop=True, filled=False)\n",
    "        src_hs = np.ma.masked_array(es.hillshade(src_masked[0].filled(np.nan)), mask=src_masked.mask[0])\n",
    "        plot.show(src_hs, ax=ax, transform=src_masked_tr, cmap='Greys_r', \n",
    "            aspect='equal', vmin=-150, vmax=100)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_axis_off()\n",
    "    \n",
    "    #add ground tracks\n",
    "    lc_list=[]\n",
    "    if color_by is not None:\n",
    "        for i in range(len(gdf_gts_all)):\n",
    "            row = gdf_gts_all[i:i+1]\n",
    "            coords = row.get_coordinates()\n",
    "            cmap = cmc.vik_r\n",
    "            t = row.track.iloc[0]\n",
    "            pt = row.pt.iloc[0]\n",
    "            # Prepare segments for LineCollection\n",
    "            # Prepare segments for LineCollection\n",
    "            dc_dx = np.gradient(coords.x)\n",
    "            dc_dx_idx = np.abs(dc_dx)>1e2\n",
    "            coords.loc[dc_dx_idx, 'x'] = np.nan\n",
    "            points = np.array([coords.x, coords.y]).T.reshape(-1, 1, 2)\n",
    "            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "            # Create a LineCollection\n",
    "            lc = LineCollection(segments, cmap=cmap, norm=plt.Normalize(vlims[0], vlims[1]))\n",
    "            h_plot = h_ano_lin.sel(degree=1).sel(track=t, pt=pt).polyfit_coefficients\n",
    "            if rolling is not None: \n",
    "                h_plot = np.array(pd.Series(h_plot).rolling(window=rolling, center=True, min_periods=1, \n",
    "                    win_type='gaussian').mean(std=rolling/3))\n",
    "            lc.set_array(h_plot)\n",
    "            lc.set_linewidth(line_w)\n",
    "            lc_list.append(lc)\n",
    "            ax.add_collection(lc)\n",
    "    elif color_by is None:\n",
    "        gdf_gts_all.plot(ax=ax, color=gdf_gts_all.plotcolor, linewidth=line_w)\n",
    "        gdf_gts_pp.plot(ax=ax, color='lightblue', linewidth=line_w)\n",
    "    \n",
    "    hdls = []\n",
    "    gdf_ext_all.apply(lambda p: p.buffer(4e3)).plot(ax=ax, color='None', edgecolor='white', label='grounded ice', linewidth=1, zorder=500)\n",
    "    gdf_pp.plot(ax=ax, color='None', edgecolor='black', label='grounded ice', linewidth=0.2, zorder=501)\n",
    "    gdf_ext.apply(lambda p: p.buffer(1e3)).plot(ax=ax, color='None', edgecolor='royalblue', label='floating ice', linewidth=0.4, zorder=502)\n",
    "    \n",
    "    \n",
    "    ax.axis('off')\n",
    "    #ax.text(0.5, 0.96, f'ICESat-2 ATL11 Height Change\\n Basin {basin} 2019-2024', transform=ax.transAxes, \n",
    "    #        ha='center', va='center', fontsize=major_font_size, bbox=boxprops, zorder=502)\n",
    "    # Create a ScalarMappable with the same colormap and normalization\n",
    "    norm = mcolors.Normalize(vmin=vlims[0], vmax=vlims[1])\n",
    "    sm = cm.ScalarMappable(cmap=cmc.vik_r, norm=norm)\n",
    "    sm.set_array([])  # Only needed for older versions of matplotlib\n",
    "    \n",
    "    # Add the inset axis\n",
    "    pos = ax.get_position()\n",
    "    cax_pos = [pos.x0+pos.width*0.7, pos.y0+0.13, pos.width*0.25, pos.height*0.01]\n",
    "    cax = fig.add_axes(cax_pos)\n",
    "    #fig.patches.append(Rectangle((cax_pos[0]-, cax_pos[1]), cax_pos[2]*1.25, cax_pos[3]*2,\n",
    "    #    transform=fig.transFigure, color='white', zorder=1))\n",
    "    \n",
    "    # Add a colorbar to the plot, with a specific location\n",
    "    cbar = plt.colorbar(sm, cax=cax, orientation='horizontal', fraction=0.1, pad=0.0)\n",
    "    cbar.ax.tick_params(labelsize=minor_font_size) \n",
    "    cbar.set_label('height change \\n(m yr$^{-1}$)', fontsize=minor_font_size)\n",
    "    cbar.outline.set_edgecolor('black')\n",
    "    cbar.outline.set_linewidth(0.5)\n",
    "    set_axis_color(cax, 'black')\n",
    "    \n",
    "    # Customize the colorbar ticks if needed\n",
    "    cbar.set_ticks([-1, 0, 1])\n",
    "    #cbar.set_ticklabels(['0', '0.2', '0.4', '0.6', '0.8', '1'])\n",
    "    \n",
    "    plotname = f'{plot_dir}/{basin}_dhdt_map.png'\n",
    "    if rolling is not None: plotname = f'{plot_dir}/{basin}_dhdt_avg{rolling}_map.png'\n",
    "    if save: fig.savefig(plotname, dpi=dpi, bbox_inches='tight', transparent=transparent)\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d63cba6-a159-4729-85d7-84ae479cff5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fig = make_map(color_by='', dpi=400, vlims=[-1, 1], rolling=None, save=False, transparent=True)\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "id": "70d54634-4f79-46d5-bb2f-1d19c0b083f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ensemble_plots():\n",
    "    imagery_aspect = 1.4\n",
    "    major_font_size = 16\n",
    "    minor_font_size = 16\n",
    "    line_w = 0.5\n",
    "    figsize=[8, 4]\n",
    "    legendsize=[5, 1.5]\n",
    "    \n",
    "    fig_list = []\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    boxprops = dict(boxstyle='round', facecolor='white', alpha=0.5, edgecolor='none', pad=0.2)\n",
    "    \n",
    "    hdls=[]\n",
    "    ano_cycle_fl = ds_fl.h_ano.median(dim=['x', 'track', 'pt'])\n",
    "    ano_cycle_gr = ds_gr.h_ano.median(dim=['x', 'track', 'pt'])\n",
    "    ano_cycle_pp = ds_pp.h_ano.median(dim=['x', 'track', 'pt'])\n",
    "    ax.axhline(y=0.0, linestyle='--', color='black')\n",
    "    hdl, = ax.plot(ano_cycle_fl.cycle_number, (ano_cycle_fl - ano_cycle_fl.isel(cycle_number=0)), color='red', label='floating ice')\n",
    "    hdls.append(hdl)\n",
    "    hdl, = ax.plot(ano_cycle_pp.cycle_number, (ano_cycle_pp - ano_cycle_pp.isel(cycle_number=0)), '--', color='red', label='pinning points')\n",
    "    hdls.append(hdl)\n",
    "    hdl, = ax.plot(ano_cycle_gr.cycle_number, (ano_cycle_gr - ano_cycle_gr.isel(cycle_number=0)), '-', color='lightblue', label='upstream grounded ice')\n",
    "    hdls.append(hdl)\n",
    "    # starting at 2 is 2019\n",
    "    ax.set_xlim([2, 24])\n",
    "    ax.set_ylim([-0.9, 0.9])\n",
    "    ax.set_xticks(ticks=np.arange(2, 24), minor=True)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24, 4), labels=[f'{int(c)}' for c in np.arange(2019, 2025)])\n",
    "    ax.set_yticks(ticks=[-0.5, 0.5])\n",
    "    ax.tick_params(axis='x', which='major', length=5, width=2)\n",
    "    ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "    ax.tick_params(which='both', direction='in', zorder=1, labelsize=minor_font_size)\n",
    "    ax.set_ylabel('height (m)', fontsize=minor_font_size, labelpad=-9)\n",
    "    ax.text(0.5, 0.96, 'Median Relative Height', transform=ax.transAxes, ha='center', va='top', \n",
    "    fontsize=major_font_size, bbox=boxprops)\n",
    "    #ax.legend(loc='lower left', fontsize=minor_font_size)\n",
    "    fig_list.append(fig)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig, ax = plt.subplots(figsize=legendsize)\n",
    "    ax.axis('off')\n",
    "    legend = ax.legend(handles, labels, loc='center', fontsize=minor_font_size)\n",
    "    ax.add_artist(legend)\n",
    "    fig_list.append(fig)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    #anomaly (data) count\n",
    "    ano_count_fl = ds_fl.h_ano.count(dim=['x', 'track', 'pt'])\n",
    "    ano_count_gr = ds_gr.h_ano.count(dim=['x', 'track', 'pt'])\n",
    "    ano_count_pp = ds_pp.h_ano.count(dim=['x', 'track', 'pt'])\n",
    "    \n",
    "    hdls = []\n",
    "    ax.axhline(y=1.0, linestyle='--', color='black')\n",
    "    hdl = ax.plot(ano_cycle_fl.cycle_number, ano_count_fl/ano_count_fl.median(), color='red', label=f'mean = {int(ano_count_fl.mean().data)} values')\n",
    "    hdls.append(hdl)\n",
    "    hdl = ax.plot(ano_cycle_pp.cycle_number, ano_count_pp/ano_count_pp.median(), '--', color='red', label=f'mean = {int(ano_count_pp.mean().data)} values')\n",
    "    hdls.append(hdl)\n",
    "    hdl = ax.plot(ano_cycle_gr.cycle_number, ano_count_gr/ano_count_gr.median(), '-', color='lightblue', label=f'mean = {int(ano_count_gr.mean().data)} values')\n",
    "    hdls.append(hdl)\n",
    "    ax.set_xlim([2, 24])\n",
    "    ax.set_ylim([-0.0, 1.75])\n",
    "    ax.set_yticks([0.5, 1.0, 1.5])\n",
    "    ax.set_ylabel('count fraction', fontsize=minor_font_size)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24), minor=True)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24, 4), labels=[f'{int(c)}' for c in np.arange(2019, 2025)])\n",
    "    ax.tick_params(axis='x', which='major', length=5, width=2, labelsize=minor_font_size)\n",
    "    ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "    ax.tick_params(which='both', direction='in', zorder=1, labelsize=minor_font_size)\n",
    "    ax.text(0.5, 0.96, 'Relative Elevation Count', transform=ax.transAxes, ha='center', va='top', fontsize=major_font_size, bbox=boxprops)\n",
    "    #ax.legend(loc='lower left', fontsize=minor_font_size)\n",
    "    fig_list.append(fig)\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig, ax = plt.subplots(figsize=legendsize)\n",
    "    ax.axis('off')\n",
    "    legend = ax.legend(handles, labels, loc='center', fontsize=minor_font_size)\n",
    "    ax.add_artist(legend)\n",
    "    fig_list.append(fig)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    bin_edges = np.arange(-10, 260, 10)\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:]) #for step fn\n",
    "    h_fl = ds_fl.h_abs.median(dim='cycle_number')\n",
    "    h_pp = ds_pp.h_abs.median(dim='cycle_number')\n",
    "    h_gr = ds_gr.h_abs.median(dim='cycle_number')\n",
    "    ax.hist(np.ndarray.flatten(h_gr.data), bin_edges, \n",
    "    color='lightblue', edgecolor='black', alpha=1,\n",
    "    label=f'{basin} floating ice', density=True);\n",
    "    ax.hist(np.ndarray.flatten(h_fl.data), bin_edges, \n",
    "    color='darkred', edgecolor='black', alpha=1,\n",
    "    label=f'{basin} floating ice', density=True);\n",
    "    ax.hist(np.ndarray.flatten(h_pp.data), bin_edges, \n",
    "    color='white', edgecolor='darkred', alpha=0.6, hatch=None,\n",
    "    label=f'{basin} pinning points', density=True);\n",
    "    counts, _ = np.histogram(np.ndarray.flatten(h_pp.data), bins=bin_edges, density=True)\n",
    "    ax.step(bin_centers, counts, where='mid', linestyle='-', color='white')\n",
    "    ax.step(bin_centers, counts, where='mid', linestyle='--', color='darkred')\n",
    "    bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "    ax.set_ylabel('count density', fontsize=minor_font_size, labelpad=-9)\n",
    "    ax.tick_params(axis='y', colors='white')\n",
    "    ax.set_ylim([0, 0.035])\n",
    "    ax.set_xlabel('height (m)', fontsize=minor_font_size)\n",
    "    ax.tick_params(which='both', direction='in', zorder=1, labelsize=minor_font_size)\n",
    "    ax.text(0.5, 0.96, f'Median elevation distribution', transform=ax.transAxes, ha='center', va='top', fontsize=major_font_size, bbox=boxprops)\n",
    "    ax.set_xlim([-10, 250])\n",
    "    fig_list.append(fig)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=[8, 3])\n",
    "    m = h_ano_lin.sel(degree=1).polyfit_coefficients\n",
    "    ax.hist(np.ndarray.flatten(m.data), 200, color='bisque', edgecolor='gray');\n",
    "    ax.axvline(x=m.mean(), label=f'mean={m.mean().round(3).data} m', color='purple')\n",
    "    ax.axvline(x=m.median(), label=f'median={m.median().round(3).data} m', color='cornflowerblue')\n",
    "    ax.set_ylabel('count')\n",
    "    ax.set_xlabel('height change (m/yr)')\n",
    "    ax.set_title(f'{basin} height change 2018-2024')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([-3, 3])\n",
    "    fig.savefig(f'/Users/ccroberts/Desktop/{basin}_dhdt_hist.png', dpi=200, bbox_inches='tight')\n",
    "    \n",
    "    if True==False:\n",
    "        fig_list[0].savefig(f'{plot_dir}/{basin}_median_anom.png', dpi=300, bbox_inches='tight')\n",
    "        fig_list[1].savefig(f'{plot_dir}/{basin}_median_anom_legend.png', dpi=300, bbox_inches='tight')\n",
    "        fig_list[2].savefig(f'{plot_dir}/{basin}_median_count.png', dpi=300, bbox_inches='tight')\n",
    "        fig_list[3].savefig(f'{plot_dir}/{basin}_median_count_legend.png', dpi=300, bbox_inches='tight')\n",
    "        fig_list[4].savefig(f'{plot_dir}/{basin}_h_abs_hist.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74d8e27-1c5d-4022-943b-33b7e6abd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ensemble_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d777e6-b02d-430d-8f87-64347e7b170a",
   "metadata": {},
   "source": [
    "# Plot with contexily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b3e12dc-93a5-402c-ac1d-120464914795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate value to plot\n",
    "h_ano_lin = ds_all.h_ano.polyfit('cycle_number', deg=1, skipna=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0085d968-2051-4bb7-af71-6d42c574544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make plot function\n",
    "def make_cx_plot(color_by='', dpi=600, rolling=None, vlims=[-5, 5], imagery_resolution_adjust=1, save=False):\n",
    "    # figure setup\n",
    "    imagery_aspect = 1.4\n",
    "    major_font_size = 12\n",
    "    minor_font_size = 10\n",
    "    line_w = 1.0\n",
    "    \n",
    "    # make figure and axes\n",
    "    fig = plt.figure(figsize=[15,8], dpi=dpi)\n",
    "    gs = fig.add_gridspec(3, 20)\n",
    "    axs = [fig.add_subplot(gs[:, :9])]\n",
    "    for i in range(3):\n",
    "        axs.append(fig.add_subplot(gs[i, 10:20]))\n",
    "    boxprops = dict(boxstyle='round', facecolor='white', alpha=0.5, edgecolor='none', pad=0.2)\n",
    "    \n",
    "    # plot the basemap and ground track\n",
    "    # We do this using the package `contextily`, which provides basemaps for plotting in matplotlib. \n",
    "    # Here we use ESRI's WordImagery basemap. \n",
    "    ax = axs[0]\n",
    "    \n",
    "    buffer = 0.001 * np.max([gdf_ext.total_bounds[i+2] - gdf_ext.total_bounds[i] for i in [0,1]])\n",
    "    bbox = np.array(box(*gdf_ext.total_bounds).buffer(buffer).bounds)\n",
    "    xrng = bbox[2] - bbox[0]\n",
    "    yrng = xrng*imagery_aspect\n",
    "    ymid = np.mean(bbox[[1,3]])\n",
    "    ax.set_xlim(bbox[[0,2]])\n",
    "    ax.set_ylim([ymid - yrng/2, ymid + yrng/2])\n",
    "    cx.add_basemap(ax=ax, crs=crs_antarctica, source=cx.providers.Esri.WorldImagery, \n",
    "        zoom_adjust=imagery_resolution_adjust, attribution=' ', attribution_size=3)\n",
    "    #, attribution='imagery ©ESRI (WorldImagery)', attribution_size=4)\n",
    "    txt = ax.texts[-1]\n",
    "    txt.set_position([0.98,0.01])\n",
    "    txt.set_ha('right')\n",
    "    txt.set_va('bottom')\n",
    "    \n",
    "    #add ground tracks\n",
    "    lc_list=[]\n",
    "    if color_by is not None:\n",
    "        for i in range(len(gdf_gts_all)):\n",
    "            row = gdf_gts_all[i:i+1]\n",
    "            coords = row.get_coordinates()\n",
    "            cmap = cmc.vik_r\n",
    "            t = row.track.iloc[0]\n",
    "            pt = row.pt.iloc[0]\n",
    "            # Prepare segments for LineCollection\n",
    "            # Prepare segments for LineCollection\n",
    "            dc_dx = np.gradient(coords.x)\n",
    "            dc_dx_idx = np.abs(dc_dx)>1e2\n",
    "            coords.loc[dc_dx_idx, 'x'] = np.nan\n",
    "            points = np.array([coords.x, coords.y]).T.reshape(-1, 1, 2)\n",
    "            segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "            # Create a LineCollection\n",
    "            lc = LineCollection(segments, cmap=cmap, norm=plt.Normalize(vlims[0], vlims[1]))\n",
    "            h_plot = h_ano_lin.sel(degree=1).sel(track=t, pt=pt).polyfit_coefficients\n",
    "            if rolling is not None: \n",
    "                h_plot = np.array(pd.Series(h_plot).rolling(window=rolling, center=True, min_periods=1, \n",
    "                    win_type='gaussian').mean(std=rolling/3))\n",
    "            lc.set_array(h_plot)\n",
    "            lc.set_linewidth(line_w)\n",
    "            lc_list.append(lc)\n",
    "            ax.add_collection(lc)\n",
    "    elif color_by is None:\n",
    "        gdf_gts_all.plot(ax=ax, color=gdf_gts_all.plotcolor, linewidth=line_w)\n",
    "        gdf_gts_pp.plot(ax=ax, color='lightblue', linewidth=line_w)\n",
    "    \n",
    "    hdls = []\n",
    "    gdf_pp.plot(ax=ax, color='None', edgecolor='black', label='grounded ice', linewidth=0.2, zorder=500)\n",
    "    gdf_ext.plot(ax=ax, color='None', edgecolor='royalblue', label='floating ice', linewidth=0.4, zorder=501)\n",
    "    \n",
    "    \n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, 0.96, f'ICESat-2 ATL11 Height Change\\n Basin {basin} 2019-2024', transform=ax.transAxes, \n",
    "            ha='center', va='center', fontsize=major_font_size, bbox=boxprops, zorder=502)\n",
    "        \n",
    "    \n",
    "    ax=axs[1]\n",
    "    hdls = []\n",
    "    \n",
    "    # mean values\n",
    "    \n",
    "    ano_cycle_fl = ds_fl.h_ano.median(dim=['x', 'track', 'pt'])\n",
    "    ano_cycle_pp = ds_pp.h_ano.median(dim=['x', 'track', 'pt'])\n",
    "    ax.axhline(y=0.0, linestyle='--', color='black')\n",
    "    hdl = ax.plot(ano_cycle_fl.cycle_number, (ano_cycle_fl - ano_cycle_fl.isel(cycle_number=0)), color='red', label='floating ice')\n",
    "    hdls.append(hdl)\n",
    "    hdl = ax.plot(ano_cycle_pp.cycle_number, (ano_cycle_pp - ano_cycle_pp.isel(cycle_number=0)), '-', color='lightblue', label='pinning points')\n",
    "    hdls.append(hdl)\n",
    "    # starting at 2 is 2019\n",
    "    ax.set_xlim([2, 24])\n",
    "    ax.set_ylim([-0.9, 0.9])\n",
    "    ax.set_xticks(ticks=np.arange(2, 24), minor=True)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24, 4), labels=[])\n",
    "    ax.set_yticks(ticks=[-0.5, 0.5])\n",
    "    ax.tick_params(axis='x', which='major', length=5, width=2)\n",
    "    ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "    ax.tick_params(which='both', direction='in', zorder=1, labelsize=minor_font_size)\n",
    "    ax.set_ylabel('height (m)', fontsize=minor_font_size, labelpad=-0.3)\n",
    "    ax.text(0.5, 0.96, 'Median Relative Height', transform=ax.transAxes, ha='center', va='top', \n",
    "        fontsize=major_font_size, bbox=boxprops)\n",
    "    ax.legend(loc='lower left', fontsize=minor_font_size)\n",
    "    \n",
    "    ax=axs[2]\n",
    "    \n",
    "    #anomaly (data) count\n",
    "    ano_count_fl = ds_fl.h_ano.count(dim=['x', 'track', 'pt'])\n",
    "    ano_count_pp = ds_pp.h_ano.count(dim=['x', 'track', 'pt'])\n",
    "    \n",
    "    hdls = []\n",
    "    ax.axhline(y=1.0, linestyle='--', color='black')\n",
    "    hdl = ax.plot(ano_cycle_fl.cycle_number, ano_count_fl/ano_count_fl.median(), color='red', label=f'mean = {int(ano_count_fl.mean().data)} values')\n",
    "    hdls.append(hdl)\n",
    "    hdl = ax.plot(ano_cycle_pp.cycle_number, ano_count_pp/ano_count_pp.median(), '-', color='lightblue', label=f'mean = {int(ano_count_pp.mean().data)} values')\n",
    "    hdls.append(hdl)\n",
    "    ax.set_xlim([2, 24])\n",
    "    ax.set_ylim([-0.0, 1.75])\n",
    "    ax.set_yticks([0.5, 1.0, 1.5])\n",
    "    ax.set_ylabel('count fraction', fontsize=minor_font_size)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24), minor=True)\n",
    "    ax.set_xticks(ticks=np.arange(2, 24, 4), labels=[f'{int(c)}' for c in np.arange(2019, 2025)])\n",
    "    ax.tick_params(axis='x', which='major', length=5, width=2, labelsize=minor_font_size)\n",
    "    ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "    ax.tick_params(which='both', direction='in', zorder=1, labelsize=minor_font_size)\n",
    "    ax.text(0.5, 0.96, 'Relative Elevation Count', transform=ax.transAxes, ha='center', va='top', fontsize=major_font_size, bbox=boxprops)\n",
    "    ax.legend(loc='lower left', fontsize=minor_font_size)\n",
    "    \n",
    "    # remove extra axes if no data\n",
    "    axs[3].axis('off')\n",
    "    \n",
    "    # Create a ScalarMappable with the same colormap and normalization\n",
    "    norm = mcolors.Normalize(vmin=vlims[0], vmax=vlims[1])\n",
    "    sm = cm.ScalarMappable(cmap=cmc.vik_r, norm=norm)\n",
    "    sm.set_array([])  # Only needed for older versions of matplotlib\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Add the inset axis\n",
    "    pos = axs[0].get_position()\n",
    "    cax_pos = [pos.x0+pos.width*0.63, pos.y0+0.13, pos.width*0.25, pos.height*0.02]\n",
    "    cax = fig.add_axes(cax_pos)\n",
    "    #fig.patches.append(Rectangle((cax_pos[0]-, cax_pos[1]), cax_pos[2]*1.25, cax_pos[3]*2,\n",
    "    #    transform=fig.transFigure, color='white', zorder=1))\n",
    "    \n",
    "    # Add a colorbar to the plot, with a specific location\n",
    "    cbar = plt.colorbar(sm, cax=cax, orientation='horizontal', fraction=0.1, pad=0.0)\n",
    "    cbar.ax.tick_params(labelsize=minor_font_size) \n",
    "    cbar.set_label('height change \\n(m yr$^{-1}$)', fontsize=minor_font_size)\n",
    "    cbar.outline.set_edgecolor('white')\n",
    "    cbar.outline.set_linewidth(0.5)\n",
    "    set_axis_color(cax, 'white')\n",
    "    \n",
    "    # Customize the colorbar ticks if needed\n",
    "    cbar.set_ticks([-1, 0, 1])\n",
    "    #cbar.set_ticklabels(['0', '0.2', '0.4', '0.6', '0.8', '1'])\n",
    "    \n",
    "    plotname = f'/Users/ccroberts/Desktop/{basin}_dhdt.png'\n",
    "    if rolling is not None: plotname = f'/Users/ccroberts/Desktop/{basin}_dhdt_avg{rolling}.png'\n",
    "    if save: fig.savefig(plotname, dpi=dpi, bbox_inches='tight')\n",
    "    \n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4913d14a-520c-4489-b4a0-665660acc613",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d53c3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Grid the data (incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "56ff1ae7-76a9-4c45-ab8b-3659fb7933e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate value to plot\n",
    "m = h_ano_lin.sel(degree=1).polyfit_coefficients\n",
    "lat = ds_all.latitude\n",
    "lon = ds_all.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "11dc73c6-12d6-4bfe-a8b0-7502595a0c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_m = xr.Dataset(data_vars={'m': (['lat'], m.stack(z=['track', 'pt', 'x']).values)}, coords={'lat': lat.stack(z=['track', 'pt', 'x']).values,\n",
    "    'lon': (['lat'], lon.stack(z=['track', 'pt', 'x']).values)})\n",
    "m_df = gpd.GeoDataFrame({'m': m.stack(z=['track', 'pt', 'x']), \n",
    "    'lon': lon.stack(z=['track', 'pt', 'x']),\n",
    "    'lat': lat.stack(z=['track', 'pt', 'x']),\n",
    "    'geometry': gpd.points_from_xy(lon.stack(z=['track', 'pt', 'x']), \n",
    "    lat.stack(z=['track', 'pt', 'x']))}, \n",
    "    crs=crs_latlon).dropna(how='any', ignore_index=True).to_crs(crs_antarctica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659904f0-3e6f-4f00-bdbf-43d6014befb7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define metadata for the raster\n",
    "metadata = {\n",
    "    'driver': 'GTiff',\n",
    "    'count': 1,\n",
    "    'dtype': 'float32',\n",
    "    'width': ds_m.sizes['lat'],\n",
    "    'height': ds_m.sizes['lat'],\n",
    "    'crs': 'EPSG:4326',\n",
    "    'transform': from_origin(ds_m.lat.min(), ds_m.lon.max(), 1, 1)  # Adjust transform based on your data\n",
    "}\n",
    "\n",
    "# Write the xarray.DataArray to a raster file\n",
    "with r.open('Cp-D_h_ano_lin.tif', 'w', **metadata) as dst:\n",
    "    dst.write(ds_m.values, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee3972-a8f2-4bbb-a9d9-682265563a24",
   "metadata": {},
   "source": [
    "# REMA Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0dd6757f-04cc-4d32-b82e-941bf85eaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_REMA(filename, crs):\n",
    "    src = rs.open(filename)\n",
    "    dem = src.read()\n",
    "    tr = src.transform\n",
    "    src, tr, crs = reproject_raster(src, crs)\n",
    "    return src, tr, crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78fa20a-3467-4e24-93d1-818ebd932616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load DEM\n",
    "filename = 'data/REMA/rema_mosaic_1km_v2.0/rema_mosaic_1km_v2.0_dem.tif'\n",
    "#src, tr, crs = get_REMA(filename, crs_antarctica)\n",
    "#src = src[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "99ecebf6-dbe8-4648-abac-9da981a74307",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = rs.open(filename)\n",
    "dem = src.read()\n",
    "tr = src.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4842e9c-eedb-4344-bd70-37b981c6547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rs.open(filename) as src:\n",
    "    dem = src.read()\n",
    "    tr = src.transform\n",
    "    siogz_path = 'shapes/scripps_antarctic_polygons_CR.shp'\n",
    "    gdf_siogz = gpd.read_file(siogz_path).set_crs(crs_antarctica, allow_override=True)\n",
    "    \n",
    "    bbox = shapely.to_geojson(box(*gdf_ext.total_bounds))\n",
    "    bbox = box(*gdf_ext.total_bounds)\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=[4, 8])\n",
    "    src_masked, src_masked_tr = mask(src, shapes=[gdf_gr.geometry[0].intersection(bbox)], \n",
    "        crop=True, filled=False)\n",
    "    src_hs = np.ma.masked_array(es.hillshade(src_masked[0].filled(np.nan)), mask=src_masked.mask[0])\n",
    "    plot.show(src_hs, ax=ax, transform=src_masked_tr, cmap='Greys_r', \n",
    "        aspect='equal', vmin=-150, vmax=100)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_axis_off()\n",
    "    plt.savefig('/Users/ccroberts/Desktop/rema_2.0.png', dpi=400, bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ce7f7-30d7-4bb8-9d05-e66a5c075523",
   "metadata": {},
   "source": [
    "# Make individual plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf999b5-b00f-40d0-a2e4-263d1156040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8, 3])\n",
    "h_fl = ds_fl.h_abs.median(dim='cycle_number')\n",
    "h_pp = ds_pp.h_abs.median(dim='cycle_number')\n",
    "bin_range = 10\n",
    "bins_fl = int(np.round((h_fl.max()-h_fl.min())/bin_range))\n",
    "bins_pp = int(np.round((h_pp.max()-h_pp.min())/bin_range))\n",
    "ax.hist(np.ndarray.flatten(h_fl.data), bins_fl, \n",
    "    color='darkred', edgecolor='gray', alpha=0.7,\n",
    "    label=f'{basin} floating ice', density=True);\n",
    "ax.hist(np.ndarray.flatten(h_pp.data), bins_pp, \n",
    "    color='lightblue', edgecolor='gray', alpha=0.8,\n",
    "    label=f'{basin} pinning points', density=True);\n",
    "#ax.axvline(x=m.mean(), label=f'mean={m.mean().round(3).data} m', color='purple')\n",
    "#ax.axvline(x=m.median(), label=f'median={m.median().round(3).data} m', color='cornflowerblue')\n",
    "ax.set_ylabel('count density')\n",
    "ax.set_yticks([])\n",
    "ax.set_xlabel('height (m)')\n",
    "ax.set_title(f'{basin} median elevation distribution')\n",
    "ax.legend()\n",
    "ax.set_xlim([-5, 255])\n",
    "#fig.savefig(f'/Users/ccroberts/Desktop/{basin}_h_hist.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a0432-3309-4249-9ae2-e6051a5f7d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8, 3])\n",
    "m = h_ano_lin.sel(degree=1).polyfit_coefficients\n",
    "ax.hist(np.ndarray.flatten(m.data), 200, color='bisque', edgecolor='gray');\n",
    "ax.axvline(x=m.mean(), label=f'mean={m.mean().round(3).data} m', color='purple')\n",
    "ax.axvline(x=m.median(), label=f'median={m.median().round(3).data} m', color='cornflowerblue')\n",
    "ax.set_ylabel('count')\n",
    "ax.set_xlabel('height change (m/yr)')\n",
    "ax.set_title(f'{basin} height change 2018-2024')\n",
    "ax.legend()\n",
    "ax.set_xlim([-3, 3])\n",
    "fig.savefig(f'/Users/ccroberts/Desktop/{basin}_dhdt_hist.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb9e4c-650d-4d50-a309-83d20027a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 3])\n",
    "plt.plot(ds_fl.cycle_number.data, ds_fl.h_abs.median(dim=['track', 'pt', 'x']), color='red', label=f'{basin} floating ice')\n",
    "plt.plot(ds_pp.cycle_number.data, ds_pp.h_abs.median(dim=['track', 'pt', 'x']), color='lightblue', label=f'{basin} pinning points')\n",
    "# starting at 2 is 2019\n",
    "#plt.xlim([2, 23])\n",
    "plt.xticks(ticks=np.arange(2, 23), labels=[f'{int(2018+((c+2)/4))}' if ((c+2)%4)==0 else '' for c in np.arange(2, 23)])\n",
    "plt.tick_params(direction='in')\n",
    "plt.xlabel('cycle')\n",
    "plt.ylabel('median height (m)')\n",
    "plt.title(f'Basin {basin} median elevation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4e5a4-c0eb-4398-a9b4-08cf99c048a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cycle plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57243bee-519a-4c48-803e-7d19f03278a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare anomaly methods\n",
    "# Grid up the data\n",
    "# plot the grid to see change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32642113-e61e-422a-aaf3-a27da133b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all.count(dim=['track', 'pt']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1377be35-2b6a-4d82-9955-069d7f266eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all.isel(cycle_number=4).count(dim=['track', 'pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ffd1c-7ccc-4f0d-96d3-66a22d82f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all.h_ano.isel(cycle_number=1).count(dim=['track', 'pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ceef0-e754-478f-8831-a750ec2b53b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 4])\n",
    "#plotdict = {f'ano_{t}_{pt}': dss.h_med.sel(track=t, pt=pt) for t in dss.track.values for pt in dss.pt.values}\n",
    "#for p in plotdict: ax.plot(plotdict[p].cycle_number, plotdict[p], '.', color='black', alpha=0.1)\n",
    "#ax.axhline(y=0.0, linestyle='--', color='black')\n",
    "ax.plot(dss.cycle_number, dss.h_med.max(dim=['track', 'pt']), color='lightcoral')\n",
    "ax.plot(dss.cycle_number, dss.h_med.median(dim=['track', 'pt']), color='red', label='median')\n",
    "ax.plot(dss.cycle_number, dss.h_med.mean(dim=['track', 'pt']), color='blue', label='mean')\n",
    "ax.plot(dss.cycle_number, dss.h_med.min(dim=['track', 'pt']), color='lightcoral')\n",
    "#ax.plot(dss_pp.cycle_number, dss_pp.h_med.median(dim=['track', 'pt']), '-', color='royalblue', label='Cp-D pinning points')\n",
    "# starting at 2 is 2019\n",
    "ax.set_xlim([2, 23])\n",
    "#ax.set_ylim([-4.5, 4.5])\n",
    "#ax.set_ylim([-0.9, 0.9])\n",
    "\n",
    "ax.set_xticks(ticks=np.arange(2, 23), minor=True)\n",
    "ax.set_xticks(ticks=np.arange(2, 23, 4), labels=[f'{int(c)}' for c in np.arange(2019, 2025)])\n",
    "ax.tick_params(axis='x', which='major', length=5, width=2)\n",
    "ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "ax.tick_params(which='both', direction='out', zorder=1)\n",
    "\n",
    "ax.set_xlabel('cycle')\n",
    "ax.set_ylabel('elevation (m)')\n",
    "ax.set_title('Basin Cp-D: floating ice elevations')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd3223-bf95-4fee-9712-1c09bcd7d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 4])\n",
    "#plotdict = {f'ano_{t}_{pt}': dss_pp.h_med.sel(track=t, pt=pt) for t in dss_pp.track.values for pt in dss_pp.pt.values}\n",
    "#for p in plotdict: ax.plot(plotdict[p].cycle_number, plotdict[p], color='lightgray')\n",
    "#ax.axhline(y=0.0, linestyle='--', color='black')\n",
    "ax.plot(dss_pp.cycle_number, dss_pp.h_med.max(dim=['track', 'pt']), color='lightcoral')\n",
    "ax.plot(dss_pp.cycle_number, dss_pp.h_med.median(dim=['track', 'pt']), color='red', label='median')\n",
    "ax.plot(dss_pp.cycle_number, dss_pp.h_med.mean(dim=['track', 'pt']), color='blue', label='mean')\n",
    "ax.plot(dss_pp.cycle_number, dss_pp.h_med.min(dim=['track', 'pt']), color='lightcoral')\n",
    "#ax.plot(dss_pp.cycle_number, dss_pp.h_med.median(dim=['track', 'pt']), '-', color='royalblue', label='Cp-D pinning points')\n",
    "# starting at 2 is 2019\n",
    "ax.set_xlim([2, 23])\n",
    "#ax.set_ylim([-4.5, 4.5])\n",
    "#ax.set_ylim([-0.9, 0.9])\n",
    "\n",
    "ax.set_xticks(ticks=np.arange(2, 23), minor=True)\n",
    "ax.set_xticks(ticks=np.arange(2, 23, 4), labels=[f'{int(c)}' for c in np.arange(2019, 2025)])\n",
    "ax.tick_params(axis='x', which='major', length=5, width=2)\n",
    "ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "ax.tick_params(which='both', direction='out', zorder=1)\n",
    "\n",
    "ax.set_xlabel('cycle')\n",
    "ax.set_ylabel('elevation (m)')\n",
    "ax.set_title('Basin Cp-D: pinning point elevations')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d09a8bf-e336-4ae0-a7e0-e9086bba86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ano_cycle = dss.h_ano.median(dim=['track', 'pt'])\n",
    "ano_cycle_std = dss.h_ano.std(dim=['track', 'pt'])\n",
    "ano_cycle_pp = dss_pp.h_ano.median(dim=['track', 'pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f462a7d8-de09-4ede-bb1c-6ebef6857860",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[10, 4])\n",
    "#plotdict = {f'ano_{t}_{pt}': dss.h_med.sel(track=t, pt=pt) for t in dss.track.values for pt in dss.pt.values}\n",
    "#for p in plotdict: ax.plot(plotdict[p].cycle_number, (plotdict[p] - plotdict[p].sel(cycle_number=3)), color='lightgray')\n",
    "ax.axhline(y=0.0, linestyle='--', color='black')\n",
    "ax.plot(ano_cycle.cycle_number, (ano_cycle - ano_cycle.isel(cycle_number=0)), color='red', label='Cp-D floating ice')\n",
    "ax.plot(ano_cycle_pp.cycle_number, (ano_cycle_pp - ano_cycle_pp.isel(cycle_number=0)), '-', color='royalblue', label='Cp-D pinning points')\n",
    "# starting at 2 is 2019\n",
    "ax.set_xlim([2, 23])\n",
    "#ax.set_ylim([-4.5, 4.5])\n",
    "#ax.set_ylim([-0.9, 0.9])\n",
    "\n",
    "ax.set_xticks(ticks=np.arange(2, 23), minor=True)\n",
    "ax.set_xticks(ticks=np.arange(2, 23, 4), labels=[f'{int(c)}' for c in np.arange(2019, 2025)])\n",
    "ax.tick_params(axis='x', which='major', length=5, width=2)\n",
    "ax.tick_params(axis='x', which='minor', length=3, width=1)\n",
    "ax.tick_params(which='both', direction='out', zorder=1)\n",
    "\n",
    "ax.set_xlabel('cycle')\n",
    "ax.set_ylabel('height change (m)')\n",
    "ax.set_title('Basin Cp-D')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd078d22-747b-43a1-a3da-07f27bfa1ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8, 3])\n",
    "plt.plot(mean_cycle.cycle_number, dss.h_med.median(dim=['track', 'pt']), color='red', label='Cp-D floating ice')\n",
    "plt.plot(mean_cycle_pp.cycle_number, dss_pp.h_med.median(dim=['track', 'pt']), '--', color='red', label='Cp-D pinning points')\n",
    "# starting at 2 is 2019\n",
    "#plt.xlim([2, 23])\n",
    "plt.xticks(ticks=np.arange(2, 23), labels=[f'{int(2018+((c+2)/4))}' if ((c+2)%4)==0 else '' for c in np.arange(2, 23)])\n",
    "plt.tick_params(direction='in')\n",
    "plt.xlabel('cycle')\n",
    "plt.ylabel('median height (m)')\n",
    "plt.title('Basin Cp-D ')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1efe1f9-86fb-4826-966f-348075678dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "6314fdd6-f932-4140-a228-64430432d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469750f-9c2d-4531-ae9d-628a361e3f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#727\n",
    "this = gdf_gts_all[197:198]\n",
    "coords = this.to_crs(crs_latlon).get_coordinates()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=[11, 7])\n",
    "ax1.plot(ds.latitude, ds.longitude-0.004, '.', label='clip_data direct', color='purple')\n",
    "ax1.plot(ds_dict_short[727].latitude.sel(pt=pt), ds_dict_short[727].longitude.sel(pt=pt)-0.002, '.', label='ds_dict_short', color='blue')\n",
    "ax1.plot(ds_dict[727].latitude.sel(pt=pt), ds_dict[727].longitude.sel(pt=pt), '.', label='ds_dict', color='orange')\n",
    "ax1.scatter(coords.y, coords.x+0.002, color='red', label='gdf_gts_all', s=1.5)\n",
    "ax1.set_title(f'Track data comparison track {track}, {pt}, cycle 13')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('latitude')\n",
    "ax1.set_ylabel('longitude')\n",
    "ax1.text(-67.11, 117.79, \n",
    "    '*n.b.*, \\'x\\' is simply a placeholder for latitude and longtiude.\\n We want it to line up with available (or NaN) elevation values',\n",
    "    color='k')\n",
    "ax2.plot(ds.x, ds.h_ano.sel(cycle_number=13, track=track, pt=pt)-2, '.', label='clip_data direct', color='purple')\n",
    "ax2.plot(ds_dict_short[727].x, ds_dict_short[727].h_ano.sel(cycle_number=13, pt=pt, track=track), '.', label='ds_dict_short', color='blue')\n",
    "ax2.plot(ds_dict[727].x, ds_dict[727].h_ano.sel(cycle_number=13, pt=pt, track=track)+2, '.', label='ds_dict', color='orange')\n",
    "#ax2.set_title(f'Height anomaly comparison track {track}, {pt}, cycle 13')\n",
    "ax2.set_xlabel(f'Pandas index \\'x\\'')\n",
    "ax2.set_ylabel('elevation anomaly (m)')\n",
    "#plt.savefig('/Users/ccroberts/Desktop/track_comparison_727.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "id": "2f3e6a60-62ee-4783-961a-d31efd41c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tides and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e227518-676a-4578-ac81-3eeebe77fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=[8, 4])\n",
    "axt = ax.twinx()\n",
    "#plt.axvspan(pp[0]/1000, pp[1]/1000, color='lightgray')\n",
    "axt.plot(ds.x_atc/1000, ds.h_abs.sel(cycle_number=3, track=track, pt=pt), color='lightgrey', label='ATL11')\n",
    "ax.plot(ds.x_atc/1000, ds.tide_cats.sel(cycle_number=3, track=track, pt=pt))\n",
    "ax.plot(ds.x_atc/1000, ds.tide_cats.interpolate_na(dim='x', method='linear', fill_value='extrapolate').sel(cycle_number=3, track=track, pt=pt), label='linear')\n",
    "ax.plot(ds.x_atc/1000, ds.tide_cats.interpolate_na(dim='x', method='linear').interpolate_na(dim='x', method='nearest', fill_value='extrapolate').sel(cycle_number=3, track=track, pt=pt), label='linear + nearest')\n",
    "ax.plot(ds.x_atc/1000, ds.tide_cats.sel(cycle_number=3, track=track, pt=pt), color='black', label='pyTMD output')\n",
    "ax.set_title(f'Tides interpolation, track {track}, {pt}, cycle {3}')\n",
    "ax.set_xlabel('x_atc (m)')\n",
    "ax.set_ylabel('elevation (m)')\n",
    "axt.set_ylabel('absolute elevation (m)')\n",
    "axt.tick_params(colors='grey')\n",
    "axt.yaxis.label.set_color('grey')\n",
    "ax.legend()\n",
    "axt.legend(loc=4)\n",
    "fig.savefig('/Users/ccroberts/Desktop/tides_interpolation.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a549e-d431-4726-bfd8-72579d657872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An xarray combine_by_coords test\n",
    "\n",
    "def combine_by_coords_problem(name, join=\"outer\"):\n",
    "\n",
    "    da0 = [['a10', 'a20', 'a30'],['b10', 'b20', 'b30'], ['c10', 'c20', 'c30']]\n",
    "    da1 = [['c40', 'c50', 'c60'], ['d40', 'd50', 'd60']] \n",
    "    ds0 = xr.Dataset({'data': (['x1', name], da0)}, coords={\"x1\": ['a', 'b', 'c'], name: [10, 20, 30]})\n",
    "    ds1 = xr.Dataset({'data': (['x1', name], da1)}, coords={\"x1\": ['c', 'd'], name: [40, 50, 60]})\n",
    "\n",
    "    return xr.combine_by_coords([ds0, ds1], join=join)\n",
    "\n",
    "#combine_by_coords_problem(\"x0\") # concatenates 1, 2, 3, 4, 5, 6\n",
    "#combine_by_coords_problem(\"x2\") # concatenates 10, 20, 30, 40, 50, 60\n",
    "\n",
    "out = combine_by_coords_problem(\"x2\", join='outer')\n",
    "out.sel(x1='d', x2=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba56dad3-ae84-45a0-a128-f57a52b17721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a line collection test\n",
    "\n",
    "cmap = cmc.vik\n",
    "this = gdf_gts_all[197:198]  #track 727\n",
    "these = [gdf_gts_all[197:198], gdf_gts_all[196:197]]\n",
    "#these = [gdf_gts_all[196:197]]\n",
    "\n",
    "# Plotting\n",
    "fig, (ax, ax1) = plt.subplots(1, 2, figsize=[10, 4])\n",
    "lc_list = []\n",
    "for this in these:\n",
    "    # Prepare segments for LineCollection\n",
    "    points = np.array([this.get_coordinates().x, this.get_coordinates().y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    # Create a LineCollection\n",
    "    lc = LineCollection(segments, cmap=cmap, label=f'{this.pt.iloc[0]}', norm=plt.Normalize(-2, 2))\n",
    "    lc.set_array(ds_dict[this.track.iloc[0]].h_ano.mean(dim='cycle_number').sel(track=this.track.iloc[0], pt=this.pt.iloc[0]))\n",
    "    #lc.set_array(ds_dict[these[1].track.iloc[0]].h_ano.mean(dim='cycle_number').sel(track=these[1].track.iloc[0], pt=these[1].pt.iloc[0]))\n",
    "    lc.set_linewidth(4)\n",
    "    lc_list.append(lc)\n",
    "    \n",
    "    ax.add_collection(lc)\n",
    "    ax.autoscale()\n",
    "\n",
    "    ax1.plot(ds_dict[this.track.iloc[0]].h_ano.mean(dim='cycle_number').sel(track=this.track.iloc[0], pt=this.pt.iloc[0]), \n",
    "             label=f'{this.pt.iloc[0]}')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "# Adding colorbar\n",
    "cb = fig.colorbar(lc, ax=ax, label='line color')\n",
    "\n",
    "# Creating a custom legend handle\n",
    "#cmap_colors = cmap(np.linspace(0, 1, 256))\n",
    "#cmap_gradient = [patches.Patch(facecolor=c, edgecolor=c, label=cmap.name) for c in cmap_colors]\n",
    "#ax.legend()#(handles=[cmap_gradient], labels=['color gradient line'], handler_map={list: HandlerTuple(ndivide=None, pad=0)})\n",
    "ax.set_ylim([-1.182e6, -1.171e6])\n",
    "ax.set_xlim([2.2230e6, 2.2430e6])\n",
    "ax1.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d31cd22-3cbb-4759-883d-3c9474742f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful but not in use\n",
    "def find_intersect_indices(mask, gt_this, gt_this_pts):\n",
    "    intersect = mask.clip(gt_this.bounds.values[0]).explode(ignore_index=True).exterior.intersection(gt_this.geometry.iloc[0])\n",
    "    intersect = intersect[~intersect.is_empty].explode(ignore_index=True)\n",
    "    return [gt_this_pts.geometry.distance(i).idxmin() for i in intersect]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fresh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
